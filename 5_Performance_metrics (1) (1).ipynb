{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "\n",
    "## A. Compute performance metrics for the given data '5_a.csv'\n",
    " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          y     proba\n",
       "0      1.0  0.637387\n",
       "1      1.0  0.635165\n",
       "2      1.0  0.766586\n",
       "3      1.0  0.724564\n",
       "4      1.0  0.889199\n",
       "...    ...       ...\n",
       "10095  1.0  0.665371\n",
       "10096  1.0  0.607961\n",
       "10097  1.0  0.777724\n",
       "10098  1.0  0.846036\n",
       "10099  1.0  0.679507\n",
       "\n",
       "[10100 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a=pd.read_csv('5_a.csv')\n",
    "df_a.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yg8uUJvGAfCM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          y     proba  y_pred\n",
       "0      1.0  0.637387       1\n",
       "1      1.0  0.635165       1\n",
       "2      1.0  0.766586       1\n",
       "3      1.0  0.724564       1\n",
       "4      1.0  0.889199       1\n",
       "...    ...       ...     ...\n",
       "10095  1.0  0.665371       1\n",
       "10096  1.0  0.607961       1\n",
       "10097  1.0  0.777724       1\n",
       "10098  1.0  0.846036       1\n",
       "10099  1.0  0.679507       1\n",
       "\n",
       "[10100 rows x 3 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here for task A\n",
    "\n",
    "df_a['y_pred']= df_a['proba'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "df_a.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive =  10000\n",
      "negative =  100\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0 \n",
    "for i in range (0, len(df_a)):\n",
    "    if df_a[\"y\"].loc[i] == 1:\n",
    "        pos += 1\n",
    "    elif df_a[\"y\"].loc[i] == 0:\n",
    "        neg += 1\n",
    "        \n",
    "print(\"positive = \", pos)\n",
    "print(\"negative = \", neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVE =  0\n",
      "FALSE POSITIVE =  100\n",
      "TRUE NEGATIVE =  0\n",
      "TRUE POSITIVE =  10000\n"
     ]
    }
   ],
   "source": [
    "def conf_matrix(df_a):\n",
    "    \n",
    "    tn = len(df_a[(df_a['y'] == 0) & (df_a['y_pred'] == 0)])\n",
    "    tp = len(df_a[(df_a['y'] == 1) & (df_a['y_pred'] == 1)]) \n",
    "    fn = len(df_a[(df_a['y'] == 1) & (df_a['y_pred'] == 0)])\n",
    "    fp = len(df_a[(df_a['y'] == 0) & (df_a['y_pred'] == 1)])\n",
    "    \n",
    "    return fn,fp,tn,tp\n",
    "\n",
    "FN,FP,TN,TP = conf_matrix(df_a)\n",
    "print(\"FALSE NEGATIVE = \",FN)\n",
    "print(\"FALSE POSITIVE = \",FP)\n",
    "print(\"TRUE NEGATIVE = \",TN)\n",
    "print(\"TRUE POSITIVE = \",TP )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE : 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "def f1_score(df_a):\n",
    "    \n",
    "    fn, fp, tn,tp = conf_matrix(df_a)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)                    \n",
    "    f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    \n",
    "    return f1\n",
    "\n",
    "f1 = f1_score(df_a)\n",
    "print(\"F1 SCORE =\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY VALUE : 0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "def accuracy(df_a):\n",
    "    \n",
    "    fn,fp,tn,tp = conf_matrix(df_a)\n",
    "    acc = ((tp + tn) / (tp + fp + fn + tn)) \n",
    "    return acc\n",
    "\n",
    "acc = accuracy(df_a)\n",
    "print('ACCURACY =',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC VALUE : 0.48829900000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def auc_score(df_a):\n",
    "    \n",
    "    tpr_array = []\n",
    "    fpr_array = []\n",
    "    sort = df_a.sort_values(\"proba\", ascending = False) \n",
    "    \n",
    "    for i in range(0,len(sort)):\n",
    "        \n",
    "        sort['y_pred'] = np.where(sort['proba'] >= sort.iloc[i]['proba'],1 ,0) \n",
    "        FN, FP, TN, TP = conf_matrix(sort)  \n",
    "        fpr_rate = FP / (TN + FP)\n",
    "        tpr_rate = TP / (TP + FN)\n",
    "        \n",
    "        tpr_array.append(tpr_rate)\n",
    "        fpr_array.append(fpr_rate)\n",
    "        \n",
    "    x = np.trapz(tpr_array, fpr_array)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "auc = auc_score(df_a)\n",
    "print('AUC =',auc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "\n",
    "\n",
    "## B. Compute performance metrics for the given data '5_b.csv'\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  0.0  0.281035\n",
       "1  0.0  0.465152\n",
       "2  0.0  0.352793\n",
       "3  0.0  0.157818\n",
       "4  0.0  0.276648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b=pd.read_csv('5_b.csv')\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          y     proba  y_pred\n",
       "0      0.0  0.281035       0\n",
       "1      0.0  0.465152       0\n",
       "2      0.0  0.352793       0\n",
       "3      0.0  0.157818       0\n",
       "4      0.0  0.276648       0\n",
       "...    ...       ...     ...\n",
       "10095  0.0  0.474401       0\n",
       "10096  0.0  0.128403       0\n",
       "10097  0.0  0.499331       0\n",
       "10098  0.0  0.157616       0\n",
       "10099  0.0  0.296618       0\n",
       "\n",
       "[10100 rows x 3 columns]>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b['y_pred'] = df_b['proba'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "df_b.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xlLVa-cVAfCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive =  100\n",
      "negative =  10000\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0 \n",
    "\n",
    "for i in range (0, len(df_b)):\n",
    "    \n",
    "    if df_b[\"y\"].loc[i] == 1:\n",
    "        \n",
    "        pos += 1\n",
    "        \n",
    "    elif df_b[\"y\"].loc[i] == 0:\n",
    "        \n",
    "        neg += 1\n",
    "        \n",
    "print(\"positive = \", pos)\n",
    "print(\"negative = \", neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVE =  45\n",
      "FALSE POSITIVE =  239\n",
      "TRUE NEGATIVE =  9761\n",
      "TRUE POSITIVE =  55\n"
     ]
    }
   ],
   "source": [
    "def conf_matrix(df_b):\n",
    "    \n",
    "    tn = len(df_b[(df_b['y'] == 0) & (df_b['y_pred'] == 0)])\n",
    "    tp = len(df_b[(df_b['y'] == 1) & (df_b['y_pred'] == 1)]) \n",
    "    fn = len(df_b[(df_b['y'] == 1) & (df_b['y_pred'] == 0)])\n",
    "    fp = len(df_b[(df_b['y'] == 0) & (df_b['y_pred'] == 1)])\n",
    "    \n",
    "    return fn,fp,tn,tp\n",
    "\n",
    "FN, FP, TN, TP = conf_matrix(df_b)\n",
    "\n",
    "print(\"FALSE NEGATIVE = \", FN)\n",
    "print(\"FALSE POSITIVE = \", FP)\n",
    "print(\"TRUE NEGATIVE = \", TN)\n",
    "print(\"TRUE POSITIVE = \", TP )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE : 0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "def f1_score(df_b):\n",
    "    \n",
    "    fn, fp ,tn, tp = conf_matrix(df_b)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)                    \n",
    "    f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    \n",
    "    return f1\n",
    "\n",
    "f1 = f1_score(df_b)\n",
    "print(\"F1 SCORE =\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY VALUE : 0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "def accuracy(df_b):\n",
    "    \n",
    "    fn, fp, tn, tp = conf_matrix(df_b)\n",
    "    acc= ((tp + tn) / (tp + fp + fn + tn)) \n",
    "    return acc\n",
    "\n",
    "acc = accuracy(df_b)\n",
    "print('ACCURACY =',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9377570000000001\n"
     ]
    }
   ],
   "source": [
    "def auc_score(df_b):\n",
    "    \n",
    "    tpr_array= []\n",
    "    fpr_array= []\n",
    "    \n",
    "    sort = df_b.sort_values('proba', ascending = False) \n",
    "    for i in range(0,len(sort)):\n",
    "        \n",
    "        sort['y_pred'] = np.where(sort['proba'] >= sort.iloc[i]['proba'], 1, 0) \n",
    "        \n",
    "        FN,FP,TN,TP = conf_matrix(sort)  \n",
    "        fpr_rate = FP /(TN + FP)\n",
    "        tpr_rate = TP /(TP + FN)\n",
    "        \n",
    "        tpr_array.append(tpr_rate)\n",
    "        fpr_array.append(fpr_rate)\n",
    "        \n",
    "    x = np.trapz(tpr_array, fpr_array)\n",
    "    \n",
    "    return x\n",
    "\n",
    "auc = auc_score(df_b)\n",
    "print(\"AUC =\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data \n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c=pd.read_csv('5_c.csv')\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eAPjewjzAfCa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob  y_pred\n",
       "0  0  0.458521       0\n",
       "1  0  0.505037       1\n",
       "2  0  0.418652       0\n",
       "3  0  0.412057       0\n",
       "4  0  0.375579       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f = lambda x: 0 if x < 0.5 else 1\n",
    "df_c['y_pred'] = df_c['prob'].map(f)\n",
    "df_c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST THRESHOLD = 0.2300390278970873\n"
     ]
    }
   ],
   "source": [
    "def threshold(data):\n",
    "    check = 0\n",
    "    thresh = []\n",
    "    A = []\n",
    "    \n",
    "    sorted = data.sort_values('prob', ascending = False) \n",
    "    \n",
    "    for i in range(0, len(sorted)):\n",
    "        \n",
    "        if check == (sorted.iloc[i]['prob']):\n",
    "            continue\n",
    "            \n",
    "        check = sorted.iloc[i]['prob'] \n",
    "        thresh.append(check)\n",
    "        sorted['y_pred'] = np.where(sorted['prob'] >= sorted.iloc[i]['prob'], 1, 0)\n",
    "        \n",
    "        FN, FP, TN, TP = conf_matrix(sorted)\n",
    "        \n",
    "        value = 500 * FN + 100 * FP\n",
    "        A.append(value)\n",
    "        \n",
    "    index = A.index(min(A))\n",
    "    return thresh[index]\n",
    "\n",
    "best = threshold(df_c)\n",
    "print('BEST THRESHOLD =', best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "\n",
    "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
    "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sVOj-bF9AfCd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d=pd.read_csv('5_d.csv')\n",
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157200, 157200)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # write your code for task 5d\n",
    "\n",
    "\n",
    "df_d = np.loadtxt('5_d.csv',skiprows = 1, delimiter = ',')\n",
    "y = df_d[:, 0]\n",
    "y_pred = df_d[:, 1]\n",
    "\n",
    "len(y), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "uRhL1pheAfCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error=  177.16569974554707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mse = np.sum(np.power(y - y_pred, 2)) / len(df_d)\n",
    "print(\"Mean Square Error= \", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error =  0.1291202994009687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAPE = np.sum(np.absolute(y - y_pred)) / np.sum(y)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error = \", MAPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error = 0.9563582786990937\n"
     ]
    }
   ],
   "source": [
    "y_mean = np.mean(np.absolute(y))\n",
    "\n",
    "sum_of_squares = np.sum(np.power(y - y_mean, 2))\n",
    "\n",
    "residue_sum_squares = np.sum(np.power(y - y_pred, 2))\n",
    "\n",
    "coefficient_of_determination = 1 - (residue_sum_squares / sum_of_squares)\n",
    "\n",
    "print(\"R^2 error =\", coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
